{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 19:50:51.912318: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743076251.995724    1047 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743076252.022713    1047 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743076252.088048    1047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743076252.088094    1047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743076252.088100    1047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743076252.088105    1047 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-27 19:50:52.111473: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-27 19:51:02,789 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "ner_tagger = Classifier.load('ner')\n",
    "sentiment_tagger = Classifier.load('sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afinn = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I am happy\"\n",
    "afinn.score(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/304 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304/304 [03:00<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Sentiment Analysis!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "book = 'worm'\n",
    "\n",
    "ner_coref_data_dir = os.path.join('booknlp_output', book)\n",
    "characters_data_dir = os.path.join('characters', book)\n",
    "\n",
    "\n",
    "def collate_relations(\n",
    "    ner_coref_data_dir: str,\n",
    "    characters_data_dir: str\n",
    ") -> None:\n",
    "    main_characters_aliases_file_path = os.path.join(characters_data_dir, 'main_characters_aliases.json')\n",
    "\n",
    "    if not os.path.exists(main_characters_aliases_file_path):\n",
    "        raise FileNotFoundError('Missing main_characters_aliases.json in given directory!')\n",
    "\n",
    "    with open(main_characters_aliases_file_path, 'r') as file: \n",
    "        main_char_list = json.load(file)\n",
    "\n",
    "    num_chars = len(main_char_list)\n",
    "    num_chapters = len(os.listdir(ner_coref_data_dir))\n",
    "\n",
    "    relations_arr = np.zeros((num_chars, num_chars, 2, num_chapters))\n",
    "\n",
    "    for chapter in tqdm(os.listdir(ner_coref_data_dir)):\n",
    "        chapter_num = int(chapter.split('-')[1]) - 1\n",
    "        relevant_sentences_file_path = os.path.join(ner_coref_data_dir, chapter, 'relevant_sentences.csv')\n",
    "        df = pd.read_csv(relevant_sentences_file_path)\n",
    "\n",
    "        df['Sentiment'] = 0.0\n",
    "\n",
    "        context_sentiment = 0\n",
    "        context_count = 0\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            sentiment = afinn.score(row['words'])\n",
    "            # sentiment = math.sqrt(abs(sentiment)) * (-1 if sentiment < 0 else 1)\n",
    "            df.loc[idx, 'Sentiment'] = sentiment\n",
    "\n",
    "            context_sentiment += sentiment\n",
    "            context_count += 1            \n",
    "\n",
    "        # context_sentiment_avg = context_sentiment / context_count if context_count else 0\n",
    "        # df['rolling_sentiment'] = df['Sentiment'].rolling(window=10, min_periods=1, center=True).mean()\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            char_list = set(json.loads(row['characters']) + (json.loads(row['speaker']) if type(row['speaker']) is str else []))\n",
    "            if len(char_list) < 2:\n",
    "                continue\n",
    "        \n",
    "            for char1 in char_list:\n",
    "                for char2 in char_list:\n",
    "                    if char1 == char2:\n",
    "                        continue\n",
    "\n",
    "                    relations_arr[char1][char2][0][chapter_num] += df.loc[idx, 'Sentiment']\n",
    "                    relations_arr[char1][char2][1][chapter_num] += 1\n",
    "\n",
    "        df.to_csv(relevant_sentences_file_path, index=False)\n",
    "\n",
    "    character_relations_file_path = os.path.join(characters_data_dir, 'character-relations.npy')\n",
    "    np.save(character_relations_file_path, relations_arr)\n",
    "\n",
    "    print(\"Completed Sentiment Analysis!\")\n",
    "\n",
    "\n",
    "collate_relations(ner_coref_data_dir, characters_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_characters_aliases_file_path = os.path.join(characters_data_dir, 'main_characters_aliases.json')\n",
    "\n",
    "with open(main_characters_aliases_file_path, 'r') as file: \n",
    "    main_char_list = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(characters_data_dir, 'character-relations.npy')\n",
    "\n",
    "arr = np.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = [[[0, 0] for j in range(len(main_char_list))]  for i in range(len(main_char_list))]\n",
    "\n",
    "char_avgs = np.sum(arr, axis=(1, 3))\n",
    "\n",
    "for i in range(len(main_char_list)):\n",
    "    for j in range(len(main_char_list)):\n",
    "        if i==j: \n",
    "            store[i][j] = None\n",
    "            continue\n",
    "\n",
    "        opposing_avg = char_avgs[j][0]/char_avgs[j][1]\n",
    "        interaction_count = int(np.sum(arr[i][j][1]))\n",
    "\n",
    "        store[i][j][0] = np.sum(arr[i][j][0]) / interaction_count - opposing_avg if interaction_count else 0\n",
    "        store[i][j][1] = interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('interactions.json', 'w') as file:\n",
    "    json.dump(store, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['NARRATOR', 'Taylor', 'Taylor Hebert', 'Ms. Hebert', 'Skitter', 'Weaver'] 0.21136947844256185\n",
      "1 ['Tattletale', 'Lisa'] 0.5996662524861434\n",
      "2 ['Grue', 'Brian'] 0.3829009336528134\n",
      "3 ['Bitch', 'Rachel', 'Rachel Lindt'] 0.8238651807556403\n",
      "4 ['Krouse', 'Francis', 'Trickster'] 0.37036404398419986\n",
      "5 ['Coil', 'Thomas Calvert', 'Thomas', 'Calvert', 'Director Calvert', 'Commander Calvert'] nan\n",
      "6 ['Lung', 'Kenta'] 0.4861294583883752\n",
      "7 ['Noelle', 'Echidna'] 0.6453364147734706\n",
      "8 ['Imp', 'Aisha'] 0.48904302755440376\n",
      "9 ['Regent', 'Alec'] 1.1658628841607566\n",
      "10 ['Jack', 'Jack Slash'] -2.9745476847592762\n",
      "11 ['Miss Militia', 'Hannah', 'Hana'] 0.19495512764659761\n",
      "12 ['Scion', 'the Warrior', 'The golden man', 'the golden man'] nan\n",
      "13 ['Chevalier'] nan\n",
      "14 ['Bonesaw', 'Riley'] -0.8950953678474114\n",
      "15 ['Defiant', 'Armsmaster', 'Collin', 'Colin'] -1.4016337644656227\n",
      "16 ['Amy', 'Amy Dallon', 'Panacea', 'Amelia', 'Ames'] 0.20331186752529898\n",
      "17 ['Golem', 'Theo', 'Theodore Anders', 'Theodore'] nan\n",
      "18 ['Weld'] -0.4894736842105263\n",
      "19 ['Shadow Stalker', 'Sophia'] 0.9293915040183697\n",
      "20 ['Dinah', 'Dinah Alcott'] -0.15436528572254\n",
      "21 ['my dad', 'Dad', 'dad', 'Danny', 'Mr. Hebert'] -0.30300632911392406\n",
      "22 ['Emma', 'Emma Barnes'] nan\n",
      "23 ['Leviathan'] nan\n",
      "24 ['Eidolon'] 0.7304347826086957\n",
      "25 ['Dragon'] -0.09084791386271873\n",
      "26 ['Alexandria', 'Rebecca'] -3.6346863468634685\n",
      "27 ['Legend', 'Keith'] 0.9657258064516129\n",
      "28 ['Parian', 'Sabah'] 1.8235294117647058\n",
      "29 ['Tecton'] nan\n",
      "30 ['Vista', 'A small figure who could only be Vista'] -0.8817097415506958\n",
      "31 ['Mannequin'] 2.9381443298969074\n",
      "32 ['Marquis'] nan\n",
      "33 ['Kid Win'] -1.9986301369863013\n",
      "34 ['Clockblocker', 'Clocksie', 'Dennis'] -0.27060931899641577\n",
      "35 ['Cody', 'Perdition'] nan\n",
      "36 ['Teacher'] nan\n",
      "37 ['Flechette', 'Foil', 'Lily'] nan\n",
      "38 ['Siberian', 'Manton', 'William Manton'] nan\n",
      "39 ['Charlotte', 'Charlottte'] 0.1059190031152648\n",
      "40 ['Hookwolf'] -0.44393530997304587\n",
      "41 ['Bakuda'] nan\n",
      "42 ['Accord'] -2.846846846846847\n",
      "43 ['Tagg', 'Director Tagg', 'Director James Tagg'] nan\n",
      "44 ['Saint'] nan\n",
      "45 ['Behemoth'] nan\n",
      "46 ['Sierra'] -0.12464985994397759\n",
      "47 ['Sundancer', 'Marissa'] 0.18981481481481483\n",
      "48 ['Shatterbird'] 0.23586118251928023\n",
      "49 ['Cherish', 'Cherie', 'Cherie Vasil', 'A teenager with a red streak dyed into her dark hair'] 0.05813031161473081\n",
      "50 ['Faultline'] 0.34238310708898945\n",
      "51 ['Canary', 'Paige'] nan\n",
      "52 ['Victoria', 'Glory Girl'] -1.56575682382134\n",
      "53 ['Glenn'] nan\n",
      "54 ['Cuff'] nan\n",
      "55 ['Ballistic', 'Luke'] -0.5302034428794993\n",
      "56 ['Kayden', 'Purity', 'Kayden Anders'] 0.9044715447154472\n",
      "57 ['Genesis', 'Jess'] 0.2126126126126126\n",
      "58 ['the Simurgh', 'The Simurgh', 'Simurgh', 'the winged Endbringer', 'The winged Endbringer'] nan\n",
      "59 ['Triumph'] nan\n",
      "60 ['Crawler'] 0.3713819812474521\n",
      "61 ['Jamie', 'Battery'] 1.8527131782945736\n",
      "62 ['Jessica', 'Jessica Yamada', 'Mrs. Yamada', 'Ms. Yamada', 'the therapist'] nan\n",
      "63 ['Grace'] nan\n",
      "64 ['Gregor', 'Gregor the Snail'] nan\n",
      "65 ['Burnscar', 'Mimi'] nan\n",
      "66 ['Rey', 'Blasto'] nan\n",
      "67 ['Glaistig Uaine', 'The Faerie Queen', 'Valkyrie', 'Ciara'] nan\n",
      "68 ['Sveta'] nan\n",
      "69 ['Newter'] 1.0169851380042463\n",
      "70 ['the Number Man', 'The Number Man', 'Number Man', 'Kurt'] -0.883495145631068\n",
      "71 ['Satyr', 'Satyrical'] nan\n",
      "72 ['Aegis'] nan\n",
      "73 ['Ingenue'] nan\n",
      "74 ['Nilbog', 'the Goblin King'] 0.4444444444444444\n",
      "75 ['Elle', 'Labyrinth'] nan\n",
      "76 ['Nero'] nan\n",
      "77 ['Kevin', 'Kevin Norton'] nan\n",
      "78 ['Contessa', 'Fortuna', 'The woman in the suit', 'A woman , tall , in a suit , carrying nothing with her'] nan\n",
      "79 ['Kaiser', 'Max', 'Max Anders'] 0.05824811027123167\n",
      "80 ['Justin', 'Crusader'] nan\n",
      "81 ['Victor'] 1.4406015037593987\n",
      "82 ['Skidmark'] 0.32\n",
      "83 ['Leet'] -0.07211028632025451\n",
      "84 ['Gallant'] nan\n",
      "85 ['Phir Sē'] nan\n",
      "86 ['Butcher'] nan\n",
      "87 ['Wanton'] nan\n",
      "88 ['Carol', 'Brandish'] nan\n",
      "89 ['Oliver'] 0.7849462365591398\n",
      "90 ['Prism'] -3.1904761904761907\n",
      "91 ['Myrddin'] nan\n",
      "92 ['Citrine'] nan\n",
      "93 ['Night'] nan\n",
      "94 ['Valefor'] nan\n",
      "95 ['Revel'] nan\n",
      "96 ['Cricket'] 0.49\n",
      "97 ['Rime'] nan\n",
      "98 ['Brooks'] -0.601123595505618\n",
      "99 ['Chariot'] -2.0945945945945947\n",
      "100 ['Forrest'] nan\n",
      "101 ['Mark', 'Flashbang'] nan\n",
      "102 ['Biter'] nan\n",
      "103 ['Assault', 'Madcap'] nan\n",
      "104 ['Mr. Gladly'] nan\n",
      "105 ['Emily', 'Piggot'] 0.17829457364341086\n",
      "106 ['Topsy'] nan\n",
      "107 ['Pandora'] nan\n",
      "108 ['Oni Lee'] 0.15384615384615385\n",
      "109 ['Gray Boy'] nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_872/2179359057.py:9: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(i, main_char_list[i], np.sum(arr[focus_char][i][0]) / np.sum(arr[focus_char][i][1]) - opposing_avg)\n"
     ]
    }
   ],
   "source": [
    "focus_char = 5\n",
    "\n",
    "\n",
    "focus_char_avg = char_avgs[focus_char][0]/char_avgs[focus_char][1]\n",
    "\n",
    "for i in range(len(main_char_list)):\n",
    "    opposing_avg = char_avgs[i][0]/char_avgs[i][1]\n",
    "\n",
    "    print(i, main_char_list[i], np.sum(arr[focus_char][i][0]) / np.sum(arr[focus_char][i][1]) - opposing_avg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
