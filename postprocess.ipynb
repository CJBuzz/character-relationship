{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE TO SELF\n",
    "\n",
    "Search for main characters throughout the whole book first, then do a reference reassignment to top 50-70 most common characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "from get_main_char import get_main_char\n",
    "\n",
    "bookname = 'worm'\n",
    "\n",
    "ner_coref_data_dir = os.path.join('output', bookname)\n",
    "characters_data_dir = os.path.join('temp_files', bookname)\n",
    "\n",
    "get_main_char(ner_coref_data_dir, characters_data_dir)\n",
    "\n",
    "with open(os.path.join(characters_data_dir, \"main_characters.json\"), 'r') as file:\n",
    "    main_characters_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_characters_data = dict(sorted(main_characters_data.items(), key = lambda x: x[1][\"count\"], reverse=True))\n",
    "\n",
    "count = 0\n",
    "for name, det in main_characters_data.items():\n",
    "    if count == 200: \n",
    "        break\n",
    "\n",
    "    print(name)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from consolidate_main_char import consolidate_main_char\n",
    "\n",
    "consolidate_main_char(characters_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_relevant_sentences import get_relevant_sentences_in_book\n",
    "\n",
    "text_dir = os.path.join(\"text\", bookname)\n",
    "\n",
    "get_relevant_sentences_in_book(\n",
    "    ner_coref_data_dir,\n",
    "    text_dir,\n",
    "    characters_data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304/304 [00:10<00:00, 30.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Sentiment Analysis! Computing averages...\n",
      "Completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def collate_relations(\n",
    "    ner_coref_data_dir: str,\n",
    "    characters_data_dir: str\n",
    ") -> None:\n",
    "    main_characters_aliases_file_path = os.path.join(characters_data_dir, 'main_characters_aliases.json')\n",
    "\n",
    "    if not os.path.exists(main_characters_aliases_file_path):\n",
    "        raise FileNotFoundError('Missing main_characters_aliases.json in given directory!')\n",
    "\n",
    "    with open(main_characters_aliases_file_path, 'r') as file: \n",
    "        main_char_list = json.load(file)\n",
    "\n",
    "    num_chars = len(main_char_list)\n",
    "    num_chapters = len(os.listdir(ner_coref_data_dir))\n",
    "\n",
    "    relations_arr = np.zeros((num_chars, num_chars, 2, num_chapters))\n",
    "    relations_arr_avg = np.zeros((num_chars, num_chars))\n",
    "\n",
    "    for chapter_num, chapter in tqdm(enumerate(os.listdir(ner_coref_data_dir)), total=num_chapters):\n",
    "        relevant_sentences_file_path = os.path.join(ner_coref_data_dir, chapter, 'relevant_sentences.csv')\n",
    "        df = pd.read_csv(relevant_sentences_file_path)\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            char_list = json.loads(row['characters'])\n",
    "            if len(char_list) < 2:\n",
    "                continue\n",
    "\n",
    "            b = TextBlob(row['words'])\n",
    "            sentiment = b.sentiment[0]\n",
    "\n",
    "            for char1 in char_list:\n",
    "                for char2 in char_list:\n",
    "                    if char1 == char2:\n",
    "                        continue\n",
    "\n",
    "                    relations_arr[char1][char2][0][chapter_num] += sentiment**2\n",
    "                    relations_arr[char1][char2][1][chapter_num] += 1\n",
    "\n",
    "    character_relations_file_path = os.path.join(characters_data_dir, 'character-relations.npy')\n",
    "    np.save(character_relations_file_path, relations_arr)\n",
    "\n",
    "    print(\"Completed Sentiment Analysis! Computing averages...\")\n",
    "\n",
    "    for char1 in range(relations_arr_avg.shape[0]):\n",
    "        for char2 in range(relations_arr_avg.shape[1]):\n",
    "            if char1 == char2: \n",
    "                continue\n",
    "\n",
    "            count = np.sum(relations_arr[char1][char2][1])\n",
    "\n",
    "            if not count: \n",
    "                continue\n",
    "\n",
    "            relations_arr_avg[char1][char2] = np.sum(relations_arr[char1][char2][0] * relations_arr[char1][char2][1])/count\n",
    "\n",
    "    character_relations_avg_file_path = os.path.join(characters_data_dir, 'character-relations_avg.npy')\n",
    "    np.save(character_relations_avg_file_path, relations_arr_avg)\n",
    "\n",
    "    print(\"Completed!\")\n",
    "\n",
    "\n",
    "collate_relations(ner_coref_data_dir, characters_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "“I’ve killed before.\n"
     ]
    }
   ],
   "source": [
    "relevant_sentences_file_path = os.path.join(ner_coref_data_dir, 'Part-304-Interlude__End', 'relevant_sentences.csv')\n",
    "\n",
    "df = pd.read_csv(relevant_sentences_file_path)\n",
    "row = df.iloc[4]\n",
    "print(len(json.loads(row['characters'])))\n",
    "print(row['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_relations_avg_file_path = os.path.join(characters_data_dir, 'character-relations_avg.npy')\n",
    "\n",
    "relations_avg_arr = np.load(character_relations_avg_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NARRATOR', 'Taylor', 'Taylor Hebert', 'Ms. Hebert', 'Skitter', 'Weaver'] 0.6802271848141603\n",
      "['Tattletale', 'Lisa'] 0.0\n",
      "['Grue', 'Brian'] 0.1924605308981884\n",
      "['Bitch', 'Rachel', 'Rachel Lindt'] 0.208446564142903\n",
      "['Krouse', 'Francis', 'Trickster'] 0.25602252918608437\n",
      "['Coil', 'Thomas Calvert', 'Thomas', 'Calvert', 'Director Calvert', 'Commander Calvert'] 0.3073401569893443\n",
      "['Lung', 'Kenta'] 0.10481878557399392\n",
      "['Noelle', 'Echidna'] 0.21771046723888987\n",
      "['Imp', 'Aisha'] 0.2446792563348697\n",
      "['Regent', 'Alec'] 0.12677195800393445\n",
      "['Jack', 'Jack Slash'] 0.1490146896076246\n",
      "['Miss Militia', 'Hannah', 'Hana'] 0.46715924370504053\n",
      "['Scion', 'the Warrior', 'The golden man', 'the golden man'] 0.20377839468897244\n",
      "['Chevalier'] 0.16952900319789221\n",
      "['Bonesaw', 'Riley'] 0.1865560990744677\n",
      "['Defiant', 'Armsmaster', 'Collin', 'Colin'] 0.3934233644337365\n",
      "['Amy', 'Amy Dallon', 'Panacea', 'Amelia', 'Ames'] 0.3496088215948188\n",
      "['Golem', 'Theo', 'Theodore Anders', 'Theodore'] 0.031875\n",
      "['Weld'] 0.21767543859649122\n",
      "['Shadow Stalker', 'Sophia'] 0.0995899741438153\n",
      "['Dinah', 'Dinah Alcott'] 0.2869467555316992\n",
      "['my dad', 'Dad', 'dad', 'Danny', 'Mr. Hebert'] 0.4136908980919777\n",
      "['Emma', 'Emma Barnes'] 0.009479166666666667\n",
      "['Leviathan'] 0.09123815388572334\n",
      "['Eidolon'] 0.20159951404635926\n",
      "['Dragon'] 0.0422038287239499\n",
      "['Alexandria', 'Rebecca'] 0.09160590277777778\n",
      "['Legend', 'Keith'] 0.02697265625\n",
      "['Parian', 'Sabah'] 0.19032407407407406\n",
      "['Tecton'] 0.007653061224489795\n",
      "['Vista', 'A small figure who could only be Vista'] 0.31483630952380953\n",
      "['Mannequin'] 0.21981481481481482\n",
      "['Marquis'] 0.20419521604938276\n",
      "['Kid Win'] 0.6624063492063492\n",
      "['Clockblocker', 'Clocksie', 'Dennis'] 0.19400000000000003\n",
      "['Cody', 'Perdition'] 1.1180555555555556\n",
      "['Teacher'] 0.03125\n",
      "['Flechette', 'Foil', 'Lily'] 0.11404780982905985\n",
      "['Siberian', 'Manton', 'William Manton'] 0.18637709548104958\n",
      "['Charlotte', 'Charlottte'] 0.142421875\n",
      "['Hookwolf'] 6.377551020408168e-06\n",
      "['Bakuda'] 0.18780185185185186\n",
      "['Accord'] 0.7301996503496504\n",
      "['Tagg', 'Director Tagg', 'Director James Tagg'] 0.07433207357016883\n",
      "['Saint'] 0.32448863636363634\n",
      "['Behemoth'] 0.16666666666666666\n",
      "['Sierra'] 0.8640088280682645\n",
      "['Sundancer', 'Marissa'] 0.09741921768707483\n",
      "['Shatterbird'] 0.0053902062719027\n",
      "['Cherish', 'Cherie', 'Cherie Vasil', 'A teenager with a red streak dyed into her dark hair'] 0.2847083834506405\n",
      "['Faultline'] 0.23699871778155707\n",
      "['Canary', 'Paige'] 0.10614703896604938\n",
      "['Victoria', 'Glory Girl'] 0.5834653505777144\n",
      "['Glenn'] 0.0\n",
      "['Cuff'] 0.0\n",
      "['Ballistic', 'Luke'] 0.09218915343915343\n",
      "['Kayden', 'Purity', 'Kayden Anders'] 0.2667427106027596\n",
      "['Genesis', 'Jess'] 0.1683122257932864\n",
      "['the Simurgh', 'The Simurgh', 'Simurgh', 'the winged Endbringer', 'The winged Endbringer'] 0.13916666666666666\n",
      "['Triumph'] 0.01991126543209877\n",
      "['Crawler'] 0.013541666666666669\n",
      "['Jamie', 'Battery'] 0.14651785714285714\n",
      "['Jessica', 'Jessica Yamada', 'Mrs. Yamada', 'Ms. Yamada', 'the therapist'] 0.0\n",
      "['Grace'] 0.00390625\n",
      "['Gregor', 'Gregor the Snail'] 0.0\n",
      "['Burnscar', 'Mimi'] 0.00028743596203913624\n",
      "['Rey', 'Blasto'] 0.0\n",
      "['Glaistig Uaine', 'The Faerie Queen', 'Valkyrie', 'Ciara'] 0.00031249999999999984\n",
      "['Sveta'] 0.0\n",
      "['Newter'] 0.6687500000000001\n",
      "['the Number Man', 'The Number Man', 'Number Man', 'Kurt'] 0.24499999999999997\n",
      "['Satyr', 'Satyrical'] 0.16000000000000003\n",
      "['Aegis'] 0.0\n",
      "['Ingenue'] 0.0\n",
      "['Nilbog', 'the Goblin King'] 0.0\n",
      "['Elle', 'Labyrinth'] 0.17392857142857146\n",
      "['Nero'] 0.0\n",
      "['Kevin', 'Kevin Norton'] 0.0\n",
      "['Contessa', 'Fortuna', 'The woman in the suit', 'A woman , tall , in a suit , carrying nothing with her'] 0.0\n",
      "['Kaiser', 'Max', 'Max Anders'] 0.012581623795351472\n",
      "['Justin', 'Crusader'] 0.36\n",
      "['Victor'] 0.3774348589435774\n",
      "['Skidmark'] 6.377551020408168e-06\n",
      "['Leet'] 0.1139797523604342\n",
      "['Gallant'] 0.010000000000000002\n",
      "['Phir Sē'] 0.0\n",
      "['Butcher'] 2.8696051423324154e-05\n",
      "['Wanton'] 0.008000000000000002\n",
      "['Carol', 'Brandish'] 0.0\n",
      "['Oliver'] 0.013333333333333336\n",
      "['Prism'] 0.0\n",
      "['Myrddin'] 0.13999999999999999\n",
      "['Citrine'] 0.02875\n",
      "['Night'] 0.0\n",
      "['Valefor'] 0.0078125\n",
      "['Revel'] 0.0\n",
      "['Cricket'] 0.0\n",
      "['Rime'] 0.0\n",
      "['Brooks'] 0.10323971949891068\n",
      "['Chariot'] 0.16000000000000003\n",
      "['Forrest'] 0.010000000000000002\n",
      "['Mark', 'Flashbang'] 0.0\n",
      "['Biter'] 0.0\n",
      "['Assault', 'Madcap'] 0.0\n",
      "['Mr. Gladly'] 0.0\n",
      "['Emily', 'Piggot'] 0.09285714285714287\n",
      "['Topsy'] 0.0\n",
      "['Pandora'] 0.0\n",
      "['Oni Lee'] 0.0\n",
      "['Gray Boy'] 0.0\n"
     ]
    }
   ],
   "source": [
    "main_characters_aliases_file_path = os.path.join(characters_data_dir, 'main_characters_aliases.json')\n",
    "\n",
    "with open(main_characters_aliases_file_path, 'r') as file: \n",
    "    main_char_list = json.load(file)\n",
    "\n",
    "for i in range(len(main_char_list)):\n",
    "    print(main_char_list[i], relations_avg_arr[1][i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
